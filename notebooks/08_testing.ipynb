{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8: Testing\n",
    "\n",
    "Tests verify your code works correctly and catch bugs early.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Understand why testing matters\n",
    "- Write basic pytest tests\n",
    "- Test edge cases and boundary conditions\n",
    "- Use the Arrange-Act-Assert pattern\n",
    "- Run tests with `uv run pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Why Test?\n",
    "\n",
    "Imagine you write a function that works great. A week later, you add a new feature. Now the old function is broken, but you don't notice until much later.\n",
    "\n",
    "**Tests prevent this.** They're automated checks that run every time you change code.\n",
    "\n",
    "### Benefits of Testing\n",
    "\n",
    "| Benefit | Explanation |\n",
    "|---------|-------------|\n",
    "| **Confidence** | Know your code works before shipping |\n",
    "| **Catch regressions** | Changes don't break existing features |\n",
    "| **Documentation** | Tests show how code should be used |\n",
    "| **Better design** | Hard-to-test code is often poorly designed |\n",
    "| **Fearless refactoring** | Change code structure without breaking behavior |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. pytest Basics\n",
    "\n",
    "Python has several testing frameworks. We'll use **pytest** because:\n",
    "- Simple, minimal boilerplate\n",
    "- Just use `assert` (no special methods)\n",
    "- Great error messages\n",
    "- Industry standard\n",
    "\n",
    "### Naming Conventions\n",
    "\n",
    "pytest finds tests automatically if you follow these rules:\n",
    "- Test files start with `test_` (e.g., `test_calculator.py`)\n",
    "- Test functions start with `test_` (e.g., `def test_addition():`)\n",
    "- Tests go in a `tests/` directory (convention)\n",
    "\n",
    "```python\n",
    "# tests/test_calculator.py\n",
    "from calculator import add, subtract\n",
    "\n",
    "def test_add_positive_numbers():\n",
    "    assert add(2, 3) == 5\n",
    "\n",
    "def test_add_negative_numbers():\n",
    "    assert add(-1, -1) == -2\n",
    "\n",
    "def test_subtract():\n",
    "    assert subtract(5, 3) == 2\n",
    "```\n",
    "\n",
    "Run with: `uv run pytest`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Assertions\n",
    "\n",
    "`assert` is Python's way of saying \"this must be true, or something is wrong.\"\n",
    "\n",
    "If the assertion passes, nothing happens. If it fails, you get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These all pass silently\n",
    "assert 2 + 2 == 4\n",
    "assert \"hello\".upper() == \"HELLO\"\n",
    "assert len([1, 2, 3]) == 3\n",
    "assert \"cat\" in \"category\"\n",
    "assert 10 > 5\n",
    "\n",
    "print(\"All assertions passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÆ Predict Before You Run\n",
    "# Which of these assertions will FAIL? Make your prediction, then run.\n",
    "\n",
    "# assert \"Hello\" == \"hello\"          # 1. Case sensitivity\n",
    "# assert [1, 2] == [1, 2]             # 2. List equality\n",
    "# assert {1, 2} == {2, 1}             # 3. Set equality\n",
    "# assert 0.1 + 0.2 == 0.3             # 4. Float arithmetic\n",
    "# assert None == False                # 5. None vs False\n",
    "\n",
    "# Uncomment one at a time to check your predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add a message to explain what went wrong\n",
    "x = 5\n",
    "# assert x == 10, f\"Expected x to be 10, but got {x}\"\n",
    "\n",
    "# Uncomment the above to see the custom error message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Assertion Patterns\n",
    "\n",
    "```python\n",
    "# Equality\n",
    "assert result == expected\n",
    "\n",
    "# Truthiness\n",
    "assert is_valid\n",
    "assert not is_empty\n",
    "\n",
    "# Membership\n",
    "assert item in collection\n",
    "assert key in dictionary\n",
    "\n",
    "# Type checking\n",
    "assert isinstance(result, list)\n",
    "\n",
    "# Approximate equality (for floats)\n",
    "assert abs(result - expected) < 0.0001\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Testing Edge Cases\n",
    "\n",
    "The \"happy path\" is when everything works normally. But bugs hide in edge cases!\n",
    "\n",
    "### What to Test\n",
    "\n",
    "| Edge Case | Example |\n",
    "|-----------|--------|\n",
    "| Empty inputs | Empty list, empty string |\n",
    "| Single item | List with one element |\n",
    "| Boundary values | 0, -1, max value |\n",
    "| Invalid inputs | Wrong type, None |\n",
    "| Duplicates | Repeated values |\n",
    "| Special characters | Spaces, punctuation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average(numbers: list[float]) -> float:\n",
    "    \"\"\"Calculate the average of a list of numbers.\"\"\"\n",
    "    if not numbers:  # Handle empty list\n",
    "        return 0.0\n",
    "    return sum(numbers) / len(numbers)\n",
    "\n",
    "# Happy path\n",
    "assert calculate_average([1, 2, 3, 4, 5]) == 3.0\n",
    "\n",
    "# Edge cases\n",
    "assert calculate_average([]) == 0.0          # Empty list\n",
    "assert calculate_average([42]) == 42.0       # Single element\n",
    "assert calculate_average([-1, 1]) == 0.0     # Negative numbers\n",
    "assert calculate_average([0, 0, 0]) == 0.0   # All zeros\n",
    "\n",
    "print(\"All edge cases handled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üñäÔ∏è Your Turn: Identify Edge Cases\n",
    "\n",
    "For each function description, list 3-5 edge cases you'd want to test:\n",
    "\n",
    "1. `find_max(numbers)` - Find the largest number in a list\n",
    "2. `count_words(text)` - Count words in a string\n",
    "3. `is_palindrome(text)` - Check if text reads the same forwards and backwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your edge cases as comments:\n",
    "\n",
    "# find_max edge cases:\n",
    "# 1. \n",
    "# 2. \n",
    "# 3. \n",
    "\n",
    "# count_words edge cases:\n",
    "# 1. \n",
    "# 2. \n",
    "# 3. \n",
    "\n",
    "# is_palindrome edge cases:\n",
    "# 1. \n",
    "# 2. \n",
    "# 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Arrange-Act-Assert (AAA)\n",
    "\n",
    "Good tests follow a clear structure:\n",
    "\n",
    "1. **Arrange**: Set up test data and conditions\n",
    "2. **Act**: Call the function being tested\n",
    "3. **Assert**: Verify the result\n",
    "\n",
    "This makes tests easy to read and debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initials(name: str) -> str:\n",
    "    \"\"\"Get initials from a full name.\"\"\"\n",
    "    parts = name.split()\n",
    "    return \"\".join(part[0].upper() for part in parts)\n",
    "\n",
    "# Test using AAA pattern\n",
    "def test_get_initials_two_names():\n",
    "    # Arrange\n",
    "    full_name = \"john smith\"\n",
    "    expected = \"JS\"\n",
    "    \n",
    "    # Act\n",
    "    result = get_initials(full_name)\n",
    "    \n",
    "    # Assert\n",
    "    assert result == expected\n",
    "\n",
    "# Run the test\n",
    "test_get_initials_two_names()\n",
    "print(\"Test passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÆ Predict Before You Run\n",
    "# What will get_initials return for these inputs?\n",
    "\n",
    "# 1. get_initials(\"Mary Jane Watson\")  ->  ???\n",
    "# 2. get_initials(\"Cher\")              ->  ???\n",
    "# 3. get_initials(\"\")                  ->  ???  (will this crash?)\n",
    "\n",
    "# Make your predictions, then run:\n",
    "print(f\"Mary Jane Watson: {get_initials('Mary Jane Watson')}\")\n",
    "print(f\"Cher: {get_initials('Cher')}\")\n",
    "# print(f\"Empty: {get_initials('')}\")  # Try this one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Writing Test Functions\n",
    "\n",
    "In a real project, tests go in separate files. But the pattern is the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function we want to test\n",
    "def is_valid_email(email: str) -> bool:\n",
    "    \"\"\"Check if email has basic valid format.\n",
    "    \n",
    "    Requirements:\n",
    "    - Must contain exactly one @\n",
    "    - Must have non-empty username before @\n",
    "    - Must have a . in the domain after @\n",
    "    \"\"\"\n",
    "    if \"@\" not in email:\n",
    "        return False\n",
    "    parts = email.split(\"@\")\n",
    "    if len(parts) != 2:\n",
    "        return False\n",
    "    username, domain = parts\n",
    "    return bool(username) and \".\" in domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests for the email validator\n",
    "\n",
    "def test_valid_email_standard():\n",
    "    \"\"\"Standard email format should be valid.\"\"\"\n",
    "    assert is_valid_email(\"user@example.com\") == True\n",
    "\n",
    "def test_valid_email_subdomain():\n",
    "    \"\"\"Email with subdomain should be valid.\"\"\"\n",
    "    assert is_valid_email(\"user@mail.example.com\") == True\n",
    "\n",
    "def test_invalid_email_no_at():\n",
    "    \"\"\"Email without @ should be invalid.\"\"\"\n",
    "    assert is_valid_email(\"userexample.com\") == False\n",
    "\n",
    "def test_invalid_email_no_dot():\n",
    "    \"\"\"Email without . in domain should be invalid.\"\"\"\n",
    "    assert is_valid_email(\"user@example\") == False\n",
    "\n",
    "def test_invalid_email_empty_username():\n",
    "    \"\"\"Email with empty username should be invalid.\"\"\"\n",
    "    assert is_valid_email(\"@example.com\") == False\n",
    "\n",
    "# Run all tests\n",
    "test_valid_email_standard()\n",
    "test_valid_email_subdomain()\n",
    "test_invalid_email_no_at()\n",
    "test_invalid_email_no_dot()\n",
    "test_invalid_email_empty_username()\n",
    "\n",
    "print(\"All email tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üñäÔ∏è Your Turn: Write Tests for is_valid_email\n",
    "\n",
    "The tests above don't cover everything! Write tests for these cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TURN: Write additional tests\n",
    "\n",
    "def test_invalid_email_multiple_at():\n",
    "    \"\"\"Email with multiple @ should be invalid.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def test_invalid_email_empty_string():\n",
    "    \"\"\"Empty string should be invalid.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def test_valid_email_with_numbers():\n",
    "    \"\"\"Email with numbers should be valid.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Run your tests (uncomment when ready)\n",
    "# test_invalid_email_multiple_at()\n",
    "# test_invalid_email_empty_string()\n",
    "# test_valid_email_with_numbers()\n",
    "# print(\"Your tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Grading Cell\n",
    "\n",
    "# These verify your tests work correctly\n",
    "assert is_valid_email(\"a@b@c.com\") == False, \"Multiple @ should be invalid\"\n",
    "assert is_valid_email(\"\") == False, \"Empty string should be invalid\"\n",
    "assert is_valid_email(\"user123@example.com\") == True, \"Numbers in email should be valid\"\n",
    "\n",
    "print(\"‚úì Additional edge cases verified!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Running pytest from the Terminal\n",
    "\n",
    "In real projects, you don't run tests by calling functions. You use pytest:\n",
    "\n",
    "```bash\n",
    "# Run all tests\n",
    "uv run pytest\n",
    "\n",
    "# Run tests in a specific file\n",
    "uv run pytest tests/test_calculator.py\n",
    "\n",
    "# Run with verbose output (see each test name)\n",
    "uv run pytest -v\n",
    "\n",
    "# Run a specific test\n",
    "uv run pytest tests/test_calculator.py::test_add_positive_numbers\n",
    "\n",
    "# Stop at first failure\n",
    "uv run pytest -x\n",
    "```\n",
    "\n",
    "### What pytest Output Looks Like\n",
    "\n",
    "```\n",
    "$ uv run pytest -v\n",
    "========================= test session starts ==========================\n",
    "collected 5 items\n",
    "\n",
    "tests/test_calculator.py::test_add_positive PASSED                [ 20%]\n",
    "tests/test_calculator.py::test_add_negative PASSED                [ 40%]\n",
    "tests/test_calculator.py::test_subtract PASSED                    [ 60%]\n",
    "tests/test_calculator.py::test_multiply PASSED                    [ 80%]\n",
    "tests/test_calculator.py::test_divide FAILED                      [100%]\n",
    "\n",
    "================================ FAILURES ================================\n",
    "_______________________________ test_divide ______________________________\n",
    "\n",
    "    def test_divide():\n",
    ">       assert divide(10, 3) == 3.33\n",
    "E       assert 3.3333333333333335 == 3.33\n",
    "\n",
    "tests/test_calculator.py:15: AssertionError\n",
    "======================= 1 failed, 4 passed in 0.12s ====================\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Test-Driven Development (TDD)\n",
    "\n",
    "Some developers write tests BEFORE the code. This is called TDD:\n",
    "\n",
    "1. **Red**: Write a failing test\n",
    "2. **Green**: Write minimum code to pass\n",
    "3. **Refactor**: Clean up while tests still pass\n",
    "\n",
    "This forces you to think about what the code should do before worrying about how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: TDD for a word counter\n",
    "\n",
    "# Step 1: Write the tests FIRST (they'll fail!)\n",
    "def test_count_words_simple():\n",
    "    assert count_words(\"hello world\") == 2\n",
    "\n",
    "def test_count_words_empty():\n",
    "    assert count_words(\"\") == 0\n",
    "\n",
    "def test_count_words_extra_spaces():\n",
    "    assert count_words(\"  hello   world  \") == 2\n",
    "\n",
    "def test_count_words_single():\n",
    "    assert count_words(\"hello\") == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Write the implementation to make tests pass\n",
    "\n",
    "def count_words(text: str) -> int:\n",
    "    \"\"\"Count the number of words in text.\"\"\"\n",
    "    if not text.strip():\n",
    "        return 0\n",
    "    return len(text.split())\n",
    "\n",
    "# Step 3: Run all tests\n",
    "test_count_words_simple()\n",
    "test_count_words_empty()\n",
    "test_count_words_extra_spaces()\n",
    "test_count_words_single()\n",
    "\n",
    "print(\"All word count tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. What NOT to Test\n",
    "\n",
    "Not everything needs a test:\n",
    "\n",
    "- **Don't test the language**: `assert 2 + 2 == 4` (Python works)\n",
    "- **Don't test external libraries**: Trust that `json.loads()` works\n",
    "- **Don't test trivial code**: Simple getters/setters\n",
    "- **Don't test private implementation**: Focus on public behavior\n",
    "\n",
    "**DO test:**\n",
    "- Your business logic\n",
    "- Edge cases in your code\n",
    "- Integration between your components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Exercise: Test a Jeopardy Function\n",
    "\n",
    "In the Jeopardy project, you'll need to normalize answers. Here's a function - write tests for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize_answer(answer: str) -> str:\n",
    "    \"\"\"Normalize an answer for comparison.\n",
    "    \n",
    "    - Remove \"what is\", \"who is\", etc.\n",
    "    - Convert to lowercase\n",
    "    - Remove punctuation\n",
    "    - Remove extra whitespace\n",
    "    \"\"\"\n",
    "    if not answer:\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    result = answer.lower()\n",
    "    \n",
    "    # Remove common Jeopardy prefixes\n",
    "    prefixes = [\"what is \", \"what are \", \"who is \", \"who are \", \n",
    "                \"where is \", \"when is \", \"the \"]\n",
    "    for prefix in prefixes:\n",
    "        if result.startswith(prefix):\n",
    "            result = result[len(prefix):]\n",
    "            break\n",
    "    \n",
    "    # Remove punctuation\n",
    "    result = re.sub(r'[^\\w\\s]', '', result)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    result = ' '.join(result.split())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÆ Predict Before You Run\n",
    "# What will normalize_answer return for each input?\n",
    "\n",
    "# 1. \"What is Python?\"      ->  ???\n",
    "# 2. \"GEORGE WASHINGTON\"    ->  ???\n",
    "# 3. \"the United States\"    ->  ???\n",
    "# 4. \"\"                     ->  ???\n",
    "\n",
    "# Make predictions, then verify:\n",
    "print(f\"1: '{normalize_answer('What is Python?')}'\")\n",
    "print(f\"2: '{normalize_answer('GEORGE WASHINGTON')}'\")\n",
    "print(f\"3: '{normalize_answer('the United States')}'\")\n",
    "print(f\"4: '{normalize_answer('')}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üñäÔ∏è Your Turn: Write comprehensive tests for normalize_answer\n",
    "\n",
    "def test_normalize_removes_what_is():\n",
    "    \"\"\"'What is X' should become just 'x'.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def test_normalize_removes_who_is():\n",
    "    \"\"\"'Who is X' should become just 'x'.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def test_normalize_lowercase():\n",
    "    \"\"\"Should convert to lowercase.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def test_normalize_removes_punctuation():\n",
    "    \"\"\"Should remove punctuation marks.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def test_normalize_handles_empty():\n",
    "    \"\"\"Empty string should return empty string.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "def test_normalize_removes_extra_spaces():\n",
    "    \"\"\"Multiple spaces should become single space.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "# Uncomment to run your tests:\n",
    "# test_normalize_removes_what_is()\n",
    "# test_normalize_removes_who_is()\n",
    "# test_normalize_lowercase()\n",
    "# test_normalize_removes_punctuation()\n",
    "# test_normalize_handles_empty()\n",
    "# test_normalize_removes_extra_spaces()\n",
    "# print(\"All normalize_answer tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Grading Cell\n",
    "\n",
    "# Verify normalize_answer works correctly\n",
    "assert normalize_answer(\"What is Python?\") == \"python\", \"Should remove 'what is' and punctuation\"\n",
    "assert normalize_answer(\"Who is Einstein?\") == \"einstein\", \"Should remove 'who is'\"\n",
    "assert normalize_answer(\"LOUD ANSWER\") == \"loud answer\", \"Should lowercase\"\n",
    "assert normalize_answer(\"Hello, World!\") == \"hello world\", \"Should remove punctuation\"\n",
    "assert normalize_answer(\"\") == \"\", \"Empty should return empty\"\n",
    "assert normalize_answer(\"  spaced   out  \") == \"spaced out\", \"Should normalize spaces\"\n",
    "assert normalize_answer(\"the Beatles\") == \"beatles\", \"Should remove 'the'\"\n",
    "\n",
    "print(\"‚úì All normalize_answer tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Exercise: Write Tests FIRST\n",
    "\n",
    "Practice TDD: Write tests for a function that doesn't exist yet, then implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üñäÔ∏è Your Turn: Write tests first!\n",
    "#\n",
    "# Function to implement: is_valid_jeopardy_value(value)\n",
    "# - Valid values are: 200, 400, 600, 800, 1000 (regular Jeopardy)\n",
    "# - Also valid: 400, 800, 1200, 1600, 2000 (Double Jeopardy)\n",
    "# - Invalid: anything else (negative, zero, odd numbers, etc.)\n",
    "\n",
    "# Step 1: Write the tests FIRST (before implementing!)\n",
    "def test_valid_regular_jeopardy_values():\n",
    "    \"\"\"Regular Jeopardy values should be valid.\"\"\"\n",
    "    # YOUR CODE HERE - test 200, 400, 600, 800, 1000\n",
    "    pass\n",
    "\n",
    "def test_valid_double_jeopardy_values():\n",
    "    \"\"\"Double Jeopardy values should be valid.\"\"\"\n",
    "    # YOUR CODE HERE - test 400, 800, 1200, 1600, 2000\n",
    "    pass\n",
    "\n",
    "def test_invalid_values():\n",
    "    \"\"\"Invalid values should return False.\"\"\"\n",
    "    # YOUR CODE HERE - test 0, -200, 100, 500, 3000\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Now implement the function to make tests pass\n",
    "\n",
    "def is_valid_jeopardy_value(value: int) -> bool:\n",
    "    \"\"\"Check if value is a valid Jeopardy clue value.\"\"\"\n",
    "    # YOUR IMPLEMENTATION HERE\n",
    "    pass\n",
    "\n",
    "# Step 3: Run your tests\n",
    "# test_valid_regular_jeopardy_values()\n",
    "# test_valid_double_jeopardy_values()\n",
    "# test_invalid_values()\n",
    "# print(\"All Jeopardy value tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Grading Cell\n",
    "\n",
    "# Verify is_valid_jeopardy_value implementation\n",
    "valid_values = [200, 400, 600, 800, 1000, 1200, 1600, 2000]\n",
    "invalid_values = [0, -200, 100, 300, 500, 700, 900, 1100, 3000, 50]\n",
    "\n",
    "for v in valid_values:\n",
    "    assert is_valid_jeopardy_value(v) == True, f\"{v} should be valid\"\n",
    "\n",
    "for v in invalid_values:\n",
    "    assert is_valid_jeopardy_value(v) == False, f\"{v} should be invalid\"\n",
    "\n",
    "print(\"‚úì is_valid_jeopardy_value works correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Exercise: Debug with Tests\n",
    "\n",
    "This function has a bug. Write tests to find it, then fix it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letter_grade(score: int) -> str:\n",
    "    \"\"\"Convert numeric score (0-100) to letter grade.\n",
    "    \n",
    "    A: 90-100\n",
    "    B: 80-89\n",
    "    C: 70-79\n",
    "    D: 60-69\n",
    "    F: below 60\n",
    "    \"\"\"\n",
    "    if score >= 90:\n",
    "        return \"A\"\n",
    "    if score >= 80:\n",
    "        return \"B\"\n",
    "    if score >= 70:\n",
    "        return \"C\"\n",
    "    if score > 60:  # BUG: should be >= 60\n",
    "        return \"D\"\n",
    "    return \"F\"\n",
    "\n",
    "# Some tests pass...\n",
    "assert get_letter_grade(95) == \"A\"\n",
    "assert get_letter_grade(85) == \"B\"\n",
    "assert get_letter_grade(75) == \"C\"\n",
    "assert get_letter_grade(65) == \"D\"\n",
    "assert get_letter_grade(55) == \"F\"\n",
    "\n",
    "print(\"Basic tests pass... but is there a bug?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üñäÔ∏è Your Turn: Find the bug!\n",
    "# Write tests for boundary values (60, 70, 80, 90) to find the bug.\n",
    "\n",
    "# Test the boundaries:\n",
    "print(f\"Score 90: {get_letter_grade(90)}\")  # Should be A\n",
    "print(f\"Score 80: {get_letter_grade(80)}\")  # Should be B\n",
    "print(f\"Score 70: {get_letter_grade(70)}\")  # Should be C\n",
    "print(f\"Score 60: {get_letter_grade(60)}\")  # Should be D - IS IT?\n",
    "\n",
    "# What's the bug? How would you fix it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Tests are automated checks** - They run every time you change code\n",
    "2. **Use `assert`** - Simple way to check expected vs actual\n",
    "3. **Test edge cases** - Empty inputs, boundaries, errors\n",
    "4. **AAA pattern** - Arrange, Act, Assert\n",
    "5. **Run with pytest** - `uv run pytest`\n",
    "6. **TDD optional** - But writing tests first can help design\n",
    "\n",
    "### pytest Cheat Sheet\n",
    "\n",
    "```bash\n",
    "uv run pytest                    # Run all tests\n",
    "uv run pytest -v                 # Verbose output\n",
    "uv run pytest -x                 # Stop at first failure\n",
    "uv run pytest tests/test_x.py   # Run specific file\n",
    "uv run pytest -k \"email\"        # Run tests matching \"email\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Practice:** In `pylearn`, import a function from the Jeopardy project and write tests for it!\n",
    "\n",
    "**Next up:** Notebook 09 - Git & GitHub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
